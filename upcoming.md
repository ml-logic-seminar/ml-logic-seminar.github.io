<h2 style="text-align:center"> Upcoming Talks </h2>

Join our [group](https://groups.google.com/forum/#!forum/ml_logic_seminar/join 
){:target="_blank"} in order to receive emails with the link for the talks.

<div class="talks">    

  <!-- Kuldeep -->
  <div class="talk" id="kuldeep">
    <div class="speakerInfo"> 
                <img alt="Kuldeep S. Meel" src="{{site.baseurl}}/assets/img/kuldeep.jpg">
      <br>
      <a href="https://www.comp.nus.edu.sg/~meel/" target="_blank">Kuldeep Meel</a> 
      <br>
      <a href="https://www.comp.nus.edu.sg/" target="_blank">National University of Singapore</a>
    </div>
    <div class="talkInfo"> 
              <strong> Date: </strong> Monday, March 15th, 2021 @ 1PM EST.
      <br>
    <strong> Talk Title: Functional Synthesis: An Ideal Meeting Ground for Formal Methods and Machine Learning </strong>
     <br>
      <strong> Abstract: </strong> Don't we all dream of the perfect assistant whom we can just tell what to do and the assistant can figure out how to accomplish the tasks?
Formally, given a specification F(X,Y) over the set of input variables X and output variables Y, we want the asssistant, aka functional synthesis engine, to design a function
G such that (X,Y=G(X)) satisfies F.  Functional synthesis has been studied for over 150 years, dating back Boole in 1850's and yet scalability remains a core challenge.
Motivated by progress in machine learning, we design a new algorithmic framework Manthan, which views functional synthesis as a classification problem, relying on advances in constrained sampling for data generation, and advances in automated reasoning for a novel proof-guided refinement and provable verification. On an extensive and rigorous evaluation over 609 benchmarks, we demonstrate that Manthan significantly improves upon the current state of the art, solving 356 benchmarks in comparison to 280, which is the most solved by a state of the art technique; thereby, we demonstrate an increase of 76 benchmarks over the current state of the art. The significant performance improvements, along with our detailed analysis, highlights several interesting avenues of future work at the intersection of machine learning, constrained sampling, and automated reasoning. 
      <br>
      <strong> Bio: </strong> Kuldeep Meel is Sung Kah Kay Assistant Professor in the Computer Science Department of School of Computing at National University of Singapore.   His research interests lie at the intersection of Formal Methods and Artificial Intelligence. He is a recipient of 2019 NRF Fellowship for AI, and was named AI's 10 to Watch by IEEE Intelligent Systems in 2020. His work received the 2018 Ralph Budd Award for Best PhD Thesis in Engineering, 2014 Outstanding Masters Thesis Award from Vienna Center of Logic and Algorithms and Best Student Paper Award at CP 2015.He received his Ph.D. (2017) and M.S. (2014) degree from Rice University, and B. Tech. (with Honors) degree (2012) in Computer Science and Engineering from Indian Institute of Technology, Bombay.
      <br>
      <strong> Meeting Link: </strong> <a href="https://uwaterloo.webex.com/uwaterloo/j.php?MTID=m3c4e87fc8d72e02beed0c7d58de9d485" target="_blank">WebEx</a>
    </div>
  </div>
  
     <!-- Krishnaram -->
  <div class="talk" id="krishnaram">
    <div class="speakerInfo"> 
                <img alt="Stanley Bak" src="{{site.baseurl}}/assets/img/krishnaram.jpg">
      <br>
      <a href="https://www.linkedin.com/in/krishnaramkenthapadi" target="_blank">Krishnaram Kenthapadi</a> 
      <br>
      <a href="https://aws.amazon.com/ai/" target="_blank">Amazon AWS AI</a>
    </div>
    <div class="talkInfo"> 
              <strong> Date: </strong> Monday, April 12th, 2021 @ 4PM EST.
      <br>
<strong> Talk Title: Fairness, Explainability, and Privacy in AI/ML Systems</strong>
     <br>
      <strong> Abstract: </strong> How do we develop machine learning models and systems taking fairness, accuracy, explainability, and transparency into account? How do we protect the privacy of users when building large-scale AI based systems? Model fairness and explainability and protection of user privacy are considered prerequisites for building trust and adoption of AI systems in high stakes domains such as lending and healthcare requiring reliability, safety, and fairness.
<br>
We will first motivate the need for adopting a “fairness, explainability, and privacy by design” approach when developing AI/ML models and systems for different consumer and enterprise applications from the societal, regulatory, customer, end-user, and model developer perspectives. We will then focus on the application of fairness-aware ML, explainable AI, and privacy-preserving AI techniques in practice through industry case studies. We will discuss the sociotechnical dimensions and practical challenges, and conclude with the key takeaways and open challenges.
      <br>
      <strong> Bio: </strong> Krishnaram Kenthapadi is a Principal Scientist at Amazon AWS AI, where he leads the fairness, explainability, and privacy initiatives in Amazon AI platform. Until recently, he led similar efforts at LinkedIn AI team, and served as LinkedIn’s representative in Microsoft’s AI and Ethics in Engineering and Research Advisory Board. Previously, he was a Researcher at Microsoft Research, where his work resulted in product impact (and Gold Star / Technology Transfer awards), and several publications/patents. Krishnaram received his Ph.D. in Computer Science from Stanford University in 2006. He serves regularly on the program committees of KDD, WWW, WSDM, and related conferences, and co-chaired the 2014 ACM Symposium on Computing for Development. His work has been recognized through awards at NAACL, WWW, SODA, CIKM, ICML AutoML workshop, and Microsoft’s AI/ML conference. He has published 40+ papers, with 2500+ citations and filed 140+ patents (30+ granted). He has presented lectures/tutorials on <a href="https://sites.google.com/view/privacy-tutorial" target="_blank">privacy</a>, <a href="https://sites.google.com/view/fairness-tutorial" target="_blank">fairness</a>, and <a href="https://sites.google.com/view/explainable-ai-tutorial" target="_blank">explainable AI</a> at KDD ’18 ’19, WSDM ’19, WWW ’19 ’20, FAccT ’20, and AAAI ’20.
      <br>
      <strong> Meeting Link: </strong> <a href="https://uwaterloo.webex.com/uwaterloo/j.php?MTID=m1400476a87f52ae676f9f07192055634" target="_blank">WebEx</a>
    </div>
  </div>

</div>
