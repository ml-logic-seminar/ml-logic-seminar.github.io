<h2 style="text-align:center"> Upcoming Talks </h2>

Join our [group](https://groups.google.com/forum/#!forum/ml_logic_seminar/join 
){:target="_blank"} in order to receive emails with the link for the talks.

<div class="talks">  
  <!-- Aws -->
  <div class="talk" id="aws">
        <div class="speakerInfo"> 
            <img alt="Aws Albarghouthi" src="{{site.baseurl}}/assets/img/aws.jpg">
      <br>
      <a href="http://pages.cs.wisc.edu/~aws/" target="_blank">Aws Albarghouthi</a> 
      <br>
      <a href="https://www.wisc.edu/" target="_blank">University of Wisconsin-Madison</a>
    </div>
    <div class="talkInfo"> 
              <strong> Date: </strong> Monday, December 14th, 2020 @ 4PM.
      <br>
<strong> Talk Title: </strong> TBA
     <br>
      <strong> Abstract: </strong> The rise of machine learning, particularly in the form of deep learning, has created a qualitative shift in our conception of what software is and what software can accomplish. But, of course, it’s not all rainbows and butterflies. Researchers have been hard at work trying to understand the fragility of the machine-learning pipeline: from training to inference, small changes to the input can result in radical changes to the output, which can lead to security, safety, as well as ethical problems. In this talk, I will show how new techniques from software verification can help us reason about, and ensure, robustness of machine-learning techniques against training-time (poisoning) and test-time (adversarial-example) attacks.

This talk is based on joint work with Yuhao Zhang, Samuel Drews, and Loris D’Antoni.
      <br>
      <strong> Bio: </strong> Aws Albarghouthi is an assistant professor at the University of Wisconsin-Madison. He studies automated synthesis and verification of programs. He received his PhD from the University of Toronto in 2015. He has received a number of best-paper awards for his work (at FSE, UIST, and FAST), an NSF CAREER award, a Google Faculty Research Award, and Facebook Research Awards. Aws is very excited about his virtual visit to Waterloo.
      <br>
      <strong> Meeting Link: </strong> <a href="https://uwaterloo.webex.com/uwaterloo/j.php?MTID=m9457308fe0c342d8bbbdc1062a2ff5cc" target="_blank">WebEx</a>
    </div>
  </div>

  <!-- Aditya and Matthew -->
  <div class="talk" id="aditya">
    <div class="speakerInfo"> 
      <img alt="Aditya Thakur" src="{{site.baseurl}}/assets/img/aditya.jpg">
      <br>
      <a href="http://thakur.cs.ucdavis.edu/" target="_blank">Aditya Thakur</a> 
      <br>
      <a href="https://www.ucdavis.edu/" target="_blank">University of California, Davis</a>
      <br>
      <img alt="Matthew Ali Sotoudeh" src="{{site.baseurl}}/assets/img/sotoudeh.jpg">
      <br>
      <a href="https://masot.net/" target="_blank">Matthew Sotoudeh</a> 
      <br>
      <a href="https://www.ucdavis.edu/" target="_blank">University of California, Davis</a>
    </div>
    <div class="talkInfo"> 
              <strong> Date: </strong> Monday, December 21st, 2020 @ 4PM.
      <br>
<strong> Talk Title: </strong> TBA
     <br>
      <strong>Aditya Thakur's Bio: </strong> Aditya Thakur's research and teaching interests are in programming languages, automated reasoning, and software engineering. The goal of his research is to develop tools and techniques to improve the reliability and performance of software systems. His current research aims to develop explainable and scalable program analysis—tools that he would have wanted while he was working in the industry.
      <br>
      <strong>Matthew Ali Sotoudeh's Bio: </strong> Matthew Sotoudeh is currently pursuing a Bachelor of Science in Mathematics at UC Davis. He is broadly interested in understanding and explaining computational processes. His recent research has focused on exploring how ideas from the fiels of programming languages and automated reasoning can help design safer and more efficient deep learning systems. 
      <br>      
      <strong> Meeting Link: </strong><a href="https://uwaterloo.webex.com/uwaterloo/j.php?MTID=mc8a3f4b8656c02643da37f3460c03a12" target="_blank">WebEx</a>
    </div>
  </div>

  <!-- Nicolas -->
  <div class="talk" id="nicolas">
    <div class="speakerInfo"> 
                <img alt="Nicolas Papernot" src="{{site.baseurl}}/assets/img/nicolas.png">
      <br>
      <a href="https://www.papernot.fr/" target="_blank">Nicolas Papernot</a> 
      <br>
      <a href="https://www.utoronto.ca/" target="_blank">University of Toronto</a>, <a href="https://vectorinstitute.ai/" target="_blank">Vector Institute</a>
    </div>
    <div class="talkInfo"> 
              <strong> Date: </strong> Monday, January 11th, 2021 @ 1PM.
      <br>
<strong> Talk Title: </strong> A Marauder's Map of Security and Privacy in Machine Learning 
     <br>
      <strong> Bio: </strong> Nicolas Papernot is an assistant professor in the Department of Electrical and Computer Engineering at the University of Toronto. Further, he is a faculty member at the Vector Institute, where he holds a Canada CIFAR AI Chair, and a faculty affiliate at the Schwartz Reisman Institute. He earned his Ph.D. in Computer Science and Engineering at the Pennsylvania State University, working with Prof. Patrick McDaniel and supported by a Google PhD Fellowship in Security and Privacy. Nicolas received a best paper award at ICLR 2017. He is also the co-author of CleverHans, an open-source library widely adopted in the technical community to benchmark machine learning in adversarial settings, and tf.Privacy, an open-source library for training differentially private models with TensorFlow. He serves on the program committees of several conferences including ACM CCS, IEEE S&P, and USENIX Security. In 2016, he received his M.S. in Computer Science and Engineering from the Pennsylvania State University and his M.S. in Engineering Sciences from the Ecole Centrale de Lyon.
      <br>
      <strong> Meeting Link: </strong><a href="https://uwaterloo.webex.com/uwaterloo/j.php?MTID=mdfea3aea83ff27b0356dc62a164a3ea7" target="_blank">WebEx</a>
    </div>
  </div>
  
  <!-- Gautam -->
  <div class="talk" id="gautam">
    <div class="speakerInfo"> 
                <img alt="Gautam Kamath" src="{{site.baseurl}}/assets/img/gautam.jpg">
      <br>
      <a href="http://www.gautamkamath.com/" target="_blank">Gautam Kamath</a> 
      <br>
      <a href="https://uwaterloo.ca/" target="_blank">University of Waterloo</a>
    </div>
    <div class="talkInfo"> 
              <strong> Date: </strong> Monday, January 18th, 2021 @ 4PM.
      <br>
<strong> Talk Title: </strong> Robustness in unsupervised and supervised machine learning
     <br>
      <strong> Abstract: </strong> Recently, the need for robust machine learning algorithms has become apparent. Whether due to errors in data collection, model
misspecification, or adversarial attacks, contaminated datasets arise in many areas. This is an issue, as existing methods appear to be quite
brittle to small amounts of errors. Even more worryingly, these models are being deployed in many security-critical settings, such as
self-driving cars, where reliability is an absolute must. In this talk, I will describe a line of work in which we provide provable guarantees for robust machine learning in several fundamental settings. I’ll begin by discussing the problem of robust estimation of mean and covariance of a Gaussian distribution, and how to relax this to distributions with weaker assumptions on the moments. I will then describe how these methods can be used to “robustify” supervised learning algorithms by applying robust mean estimation algorithms to the gradients of the dataset. While theoretically sound, the algorithms are also realizable and efficient, and I will present experimental results on both synthetic and real-world data. Based on joint works with Ilias Diakonikolas, Daniel M. Kane, Jerry Li,
Ankur Moitra, Jacob Steinhardt, and Alistair Stewart. 
      <strong> Bio: </strong> Gautam Kamath is an Assistant Professor at the David R. Cheriton School of Computer Science at the University of Waterloo. He has a B.S. in Computer Science and Electrical and Computer Engineering from Cornell University, and an M.S. and Ph.D. in Computer Science from the Massachusetts Institute of Technology. His research interests lie in methods for statistics and machine learning, with a focus on challenges which arise in modern data
analysis, including data privacy and robustness. He was a Microsoft Research Fellow, as a part of the Simons-Berkeley Research Fellowship Program at the Simons Institute for the Theory of Computing. He is recipient of an NSERC Discovery Accelerator Supplement, and was awarded the Best Student Presentation Award at the ACM Symposium on Theory of Computing in 2012.
      <br>
      <strong> Meeting Link: </strong><a href="https://uwaterloo.webex.com/uwaterloo/j.php?MTID=m47a8b947775cdec84fd27d1a56d8bcb3" target="_blank">WebEx</a>
    </div>
  </div>
</div>
