<h2 style="text-align:center"> Upcoming Talks </h2>

Join our [group](https://groups.google.com/forum/#!forum/ml_logic_seminar/join 
){:target="_blank"} in order to receive emails with the link for the talks.

<div class="talks">  
  <!-- Aditya and Matthew -->
  <div class="talk" id="aditya">
    <div class="speakerInfo"> 
      <img alt="Aditya Thakur" src="{{site.baseurl}}/assets/img/aditya.jpg">
      <br>
      <a href="http://thakur.cs.ucdavis.edu/" target="_blank">Aditya Thakur</a> 
      <br>
      <a href="https://www.ucdavis.edu/" target="_blank">University of California, Davis</a>
      <br>
      <img alt="Matthew Ali Sotoudeh" src="{{site.baseurl}}/assets/img/sotoudeh.jpg">
      <br>
      <a href="https://masot.net/" target="_blank">Matthew Sotoudeh</a> 
      <br>
      <a href="https://www.ucdavis.edu/" target="_blank">University of California, Davis</a>
    </div>
    <div class="talkInfo"> 
              <strong> Date: </strong> Monday, December 21st, 2020 @ 4PM.
      <br>
<strong> Talk Title: </strong> Understanding and Repairing Deep Neural Networks
     <br>
      <strong> Abstract: </strong> Deep neural networks (DNNs) have been successfully applied to a wide variety of problems, including image recognition, natural-language processing, medical diagnosis, and self-driving cars. As the accuracy of DNNs has increased so has their complexity and size, making the outputs of such models difficult to meaningfully interpret. The talk describes a new symbolic representation for DNNs that allowed us to exactly compute the integrated gradients, a state-of-the-art network attribution method that until now has only been approximated.

Moreover, DNNs are far from infallible, and mistakes made by DNNs have led to loss of life, motivating research on verification and testing to find mistakes in DNNs. In contrast, the talk describes techniques and tools for repairing a trained DNN once a mistake has been discovered. We present Provable Repair of DNNs, which computes a minimal change to the parameters of a trained DNN to correct its behavior according to a given specification, and ensures that the patch is provably effective, generalizing, local, and efficient.
      <br>
      <strong>Aditya Thakur's Bio: </strong> Aditya Thakur is an assistant professor of Computer Science at the University of California, Davis. He received his Ph.D. from the University of Wisconsin, Madison, and has held positions at Google, Microsoft Research, and the University of California, Berkeley. His research interests include programming languages, machine learning, formal methods, and software engineering. He was the recipient of the Facebook Probability and Programming Research Award 2019 and 2020, and Facebook Testing and Verification Research Award 2018. 
      <br>
      <strong>Matthew Ali Sotoudeh's Bio: </strong> Matthew Sotoudeh is a senior undergraduate student at the University of California, Davis, majoring in Computer Science and Mathematics, where he is a Regents Scholar.
      <br>      
      <strong> Meeting Link: </strong><a href="https://uwaterloo.webex.com/uwaterloo/j.php?MTID=mc8a3f4b8656c02643da37f3460c03a12" target="_blank">WebEx</a>
    </div>
  </div>

  <!-- Nicolas -->
  <div class="talk" id="nicolas">
    <div class="speakerInfo"> 
                <img alt="Nicolas Papernot" src="{{site.baseurl}}/assets/img/nicolas.png">
      <br>
      <a href="https://www.papernot.fr/" target="_blank">Nicolas Papernot</a> 
      <br>
      <a href="https://www.utoronto.ca/" target="_blank">University of Toronto</a>, <a href="https://vectorinstitute.ai/" target="_blank">Vector Institute</a>
    </div>
    <div class="talkInfo"> 
              <strong> Date: </strong> Monday, January 11th, 2021 @ 1PM.
      <br>
<strong> Talk Title: </strong> A Marauder's Map of Security and Privacy in Machine Learning 
     <br>
      <strong> Bio: </strong> Nicolas Papernot is an assistant professor in the Department of Electrical and Computer Engineering at the University of Toronto. Further, he is a faculty member at the Vector Institute, where he holds a Canada CIFAR AI Chair, and a faculty affiliate at the Schwartz Reisman Institute. He earned his Ph.D. in Computer Science and Engineering at the Pennsylvania State University, working with Prof. Patrick McDaniel and supported by a Google PhD Fellowship in Security and Privacy. Nicolas received a best paper award at ICLR 2017. He is also the co-author of CleverHans, an open-source library widely adopted in the technical community to benchmark machine learning in adversarial settings, and tf.Privacy, an open-source library for training differentially private models with TensorFlow. He serves on the program committees of several conferences including ACM CCS, IEEE S&P, and USENIX Security. In 2016, he received his M.S. in Computer Science and Engineering from the Pennsylvania State University and his M.S. in Engineering Sciences from the Ecole Centrale de Lyon.
      <br>
      <strong> Meeting Link: </strong><a href="https://uwaterloo.webex.com/uwaterloo/j.php?MTID=mdfea3aea83ff27b0356dc62a164a3ea7" target="_blank">WebEx</a>
    </div>
  </div>
  
  <!-- Gautam -->
  <div class="talk" id="gautam">
    <div class="speakerInfo"> 
                <img alt="Gautam Kamath" src="{{site.baseurl}}/assets/img/gautam.jpg">
      <br>
      <a href="http://www.gautamkamath.com/" target="_blank">Gautam Kamath</a> 
      <br>
      <a href="https://uwaterloo.ca/" target="_blank">University of Waterloo</a>
    </div>
    <div class="talkInfo"> 
              <strong> Date: </strong> Monday, January 18th, 2021 @ 4PM.
      <br>
<strong> Talk Title: </strong> Robustness in unsupervised and supervised machine learning
     <br>
      <strong> Abstract: </strong> Recently, the need for robust machine learning algorithms has become apparent. Whether due to errors in data collection, model
misspecification, or adversarial attacks, contaminated datasets arise in many areas. This is an issue, as existing methods appear to be quite
brittle to small amounts of errors. Even more worryingly, these models are being deployed in many security-critical settings, such as
self-driving cars, where reliability is an absolute must. In this talk, I will describe a line of work in which we provide provable guarantees for robust machine learning in several fundamental settings. I’ll begin by discussing the problem of robust estimation of mean and covariance of a Gaussian distribution, and how to relax this to distributions with weaker assumptions on the moments. I will then describe how these methods can be used to “robustify” supervised learning algorithms by applying robust mean estimation algorithms to the gradients of the dataset. While theoretically sound, the algorithms are also realizable and efficient, and I will present experimental results on both synthetic and real-world data. Based on joint works with Ilias Diakonikolas, Daniel M. Kane, Jerry Li,
Ankur Moitra, Jacob Steinhardt, and Alistair Stewart. 
      <strong> Bio: </strong> Gautam Kamath is an Assistant Professor at the David R. Cheriton School of Computer Science at the University of Waterloo. He has a B.S. in Computer Science and Electrical and Computer Engineering from Cornell University, and an M.S. and Ph.D. in Computer Science from the Massachusetts Institute of Technology. His research interests lie in methods for statistics and machine learning, with a focus on challenges which arise in modern data
analysis, including data privacy and robustness. He was a Microsoft Research Fellow, as a part of the Simons-Berkeley Research Fellowship Program at the Simons Institute for the Theory of Computing. He is recipient of an NSERC Discovery Accelerator Supplement, and was awarded the Best Student Presentation Award at the ACM Symposium on Theory of Computing in 2012.
      <br>
      <strong> Meeting Link: </strong><a href="https://uwaterloo.webex.com/uwaterloo/j.php?MTID=m47a8b947775cdec84fd27d1a56d8bcb3" target="_blank">WebEx</a>
    </div>
  </div>
  
    <!-- Shai Ben-David -->
  <div class="talk" id="shai">
    <div class="speakerInfo"> 
                <img alt="Shai Ben-David" src="{{site.baseurl}}/assets/img/shai.jpeg">
      <br>
      <a href="https://cs.uwaterloo.ca/~shai/" target="_blank">Shai Ben-David</a> 
      <br>
      <a href="https://uwaterloo.ca/" target="_blank">University of Waterloo</a>
    </div>
    <div class="talkInfo">
      <table>
        <tr>
          <th> Date </th>
          <th> Talk Titles </th>
        </tr>
        <tr>
          <td> Monday, January 25th @4PM EST </td>
          <td> Fairness in ML </td>
        </tr>
        <tr>
          <td> Monday, February 1st @4PM EST </td>
          <td> Clustering </td>
        </tr>
        <tr>
          <td> Monday, February 8th @4PM EST </td>
          <td> Independence from ZFC result </td>
        </tr>
      </table>
    <br>
    <strong> Bio: </strong> Shai Ben-David earned his Ph.D. in mathematics from the Hebrew University in Jerusalem and has been a professor of computer science at the Technion (Israel Institute of Technology).  He held visiting faculty positions at the Australian National University, Cornell University, ETH Zurich, TTI Chicago and the Simons Institute at Berkeley. Since 2004 Shai has been a professor at the David Cheriton School of Computer Science at the University of Waterloo. Since 2019 he is also a faculty member at the Toronto Vector institute. In recent years his research focus turned to machine learning theory. Among his notable contributions in that field are pioneering steps in the analysis of domain adaptation, learnability of real-valued functions, and change detection in streaming data. Shai has also made fundamental contributions to the theory of clustering and published seminal works on average-case complexity, competitive analysis of algorithms and alternatives to worst-case complexity.
<br>
      <strong> Highlights: </strong>
      <ul>
        <li> President of the Association for Computational Learning Theory (2009-2012). </li>
        <li> Program chair for the major machine learning theory conferences (COLT and ALT, and frequent area chair for ICML, NIPS and AISTATS). </li>
        <li> Co-authored the textbook “Understanding machine learning: from theory to algorithms” (Cambridge University Press 2015). </li>
        <li> Co-author of Best Paper awards, most recently in NIPS 2018. </li>
        <li> CIFAR AI Chair. </li>
        <li> University Research Chair at U Waterloo </li>
      </ul>
      <br>
      <strong> Meeting Link: </strong> TBA
    </div>
  </div>

</div>
